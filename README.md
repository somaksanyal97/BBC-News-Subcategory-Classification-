# BBC-News-Subcategory-Classification-
BBC News subcategory classification for the HMLR Data Science Challenge using LLMs and LDA. Includes fine-grained topic modeling, transformer-based classification, named entity recognition with role tagging (e.g. politicians, musicians), and summarization of events related to April.

## ðŸŽ¯ Objective

Given the BBC News dataset, the goals of this project are to:

- ðŸ”¹ **Break down broad categories** (e.g., `Business`, `Entertainment`, `Sport`) into more meaningful **subcategories** such as:
  - `Business` â†’ *stock market*, *company news*, *mergers and acquisitions*
  - `Entertainment` â†’ *cinema*, *theatre*, *music*, *literature*, *personalities*
  - `Sport` â†’ *cricket*, *football*, *Olympics*, etc.

- ðŸ”¹ **Extract named entities** from the text and identify their **roles** (e.g., `Politician`, `TV/Film Personality`, `Musician`).

- ðŸ”¹ **Summarize articles** that describe events which:
  - Took place in **April**
  - Were **scheduled** to occur in April

## âœ¨ Key Features

- ðŸ§© **Topic Modeling:**  
  Unsupervised subcategory detection using **Latent Dirichlet Allocation (LDA)**.

- ðŸ¤– **Text Classification:**  
  Fine-tuned transformer-based **Large Language Models (LLMs)** (e.g., `DistilBERT`, `BERT`) for multi-class subcategory classification.

- ðŸ·ï¸ **NER & Role Identification:**  
  Named Entity Recognition with role classification using **SpaCy** and custom rule-based mappings.

- ðŸ“° **Summarization:**  
  Extractive and abstractive summaries of **April-related articles** using **Hugging Face Transformers**.

- ðŸ“Š **Evaluation Metrics:**  
  Performance measured using **Coherence score**.

## ðŸ“ Dataset

- **Source:** [BBC Dataset â€“ UCD](http://mlg.ucd.ie/datasets/bbc.html)

  This project uses the **raw text files** from the dataset. All preprocessing steps were implemented from scratch to ensure full control and customization.

# BBC News NLP Pipelines

This repository contains three Python scripts converted from Jupyter notebooks. They perform various NLP tasks on the BBC news dataset, focusing on topic modeling (LDA), classification and summarization using Gemma 2B + Olama, and exploratory analysis.

---

## ðŸš€ Setup

Install dependencies:
```bash
pip install -r requirements.txt
```

---

## ðŸ› ï¸ Scripts

### 1ï¸âƒ£ `lda_pipeline.py`
- Performs topic modeling using LDA.

### 2ï¸âƒ£ `gemma_olama_pipeline.py`
- Uses Gemma 2B + Olama for classification and summarization.

### 3ï¸âƒ£ `bert-pipeline.py`
- 

---

## ðŸ“‚ Structure

```
BBC-News-Subcategory-Classification-/
â”œâ”€â”€ data/                   # BBC Dataset in zip file. Please unzip the data locally after cloning
â”œâ”€â”€ results/                # Outputs (CSV files with the final outputs to be stored here)
â”œâ”€â”€ lda_pipeline.py
â”œâ”€â”€ gemma_olama_pipeline.py
â”œâ”€â”€ bert-pipeline.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âœ… Usage

Run a pipeline script (example):

```bash
python lda_pipeline.py
```

Ensure the data folder is unzipped locally after cloning. 

---



  
- **Preprocessing and Analysis**
Initial pre-processing includes:

- ðŸ“‚ Loading and organizing news articles by category  
- ðŸ§¹ Removing duplicates and cleaning text (lowercasing, removing punctuation, stopwords, etc.)  
- ðŸ§  Lemmatizing words using NLTK  
- ðŸŒ¥ï¸ Visualizing top words per category using WordClouds  
- ðŸ“ˆ Extracting top 50 frequent terms per category with `CountVectorizer`  

The goal is to uncover the key subcategories discussed within each news category to use for classification in later stages.


## ðŸ“š Citation

If you make use of the BBC dataset, please consider citing the following publication:

> D. Greene and P. Cunningham.  
> *Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering*,  
> Proceedings of the 23rd International Conference on Machine Learning (ICML), 2006.  
> [PDF](http://mlg.ucd.ie/files/publications/greene06icml.pdf) | [BibTeX](http://mlg.ucd.ie/files/publications/greene06icml.bib)

